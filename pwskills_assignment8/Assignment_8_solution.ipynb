{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b086a4f0-fef4-4eb8-9d57-775b536bf384",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b266d-3838-409d-ae10-d2db53d6f9e6",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical test used to determine whether there are any significant differences between means of two or more groups. The basic assumptions of ANOVA are as follows:\n",
    "\n",
    "Normality: The data should be normally distributed within each group.\n",
    "\n",
    "Homogeneity of variance: The variance of the data in each group should be approximately equal.\n",
    "\n",
    "Independence: The observations in each group should be independent of each other.\n",
    "\n",
    "If any of these assumptions are violated, the results of the ANOVA may not be valid. Here are some examples of violations that could impact the validity of the results:\n",
    "\n",
    "Non-normality: If the data in any of the groups is not normally distributed, this can affect the validity of the ANOVA results. For example, if the data in one group is skewed, the mean of that group may not be a good representation of the data.\n",
    "\n",
    "Heterogeneity of variance: If the variance of the data in each group is significantly different, this can affect the validity of the ANOVA results. For example, if one group has a much larger variance than the other groups, this can make it more difficult to detect differences between means.\n",
    "\n",
    "Dependence: If the observations in any of the groups are not independent, this can affect the validity of the ANOVA results. For example, if the observations in one group are paired (e.g., before and after measurements), this violates the independence assumption and can lead to spurious results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a861c-e438-4326-aa91-6d848ca54fee",
   "metadata": {},
   "source": [
    "### 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666a96e-36d8-4283-ad14-b6abb42a3957",
   "metadata": {},
   "source": [
    "There are three types of ANOVA:\n",
    "\n",
    "- One-way ANOVA: This type of ANOVA is used when there is only one independent variable, which has three or more levels (or groups). One-way ANOVA is used to determine if there are any significant differences between the means of the different levels/groups. For example, one-way ANOVA can be used to compare the average weight loss among three different diet groups.\n",
    "\n",
    "- Two-way ANOVA: This type of ANOVA is used when there are two independent variables, both of which have two or more levels. Two-way ANOVA is used to determine if there are any significant main effects (i.e., the effect of each independent variable on the dependent variable) and/or interaction effects (i.e., the combined effect of the two independent variables on the dependent variable). For example, two-way ANOVA can be used to compare the average sales of two different products (product A and product B) in two different regions (North and South).\n",
    "\n",
    "- MANOVA (Multivariate Analysis of Variance): This type of ANOVA is used when there are two or more dependent variables (i.e., outcome variables) and one or more independent variables. MANOVA is used to determine if there are any significant differences between the means of the dependent variables across the different levels of the independent variable. For example, MANOVA can be used to compare the average scores on multiple personality traits (e.g., extroversion, agreeableness, neuroticism) between different age groups (young, middle-aged, and old)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f3c58-8177-492c-8a9d-007f344bbbda",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669b3fc-262b-4806-82c5-70ab17ba5db0",
   "metadata": {},
   "source": [
    "Partitioning of variance in ANOVA (Analysis of Variance) refers to the process of decomposing the total variation in the data into different sources of variation. In other words, ANOVA breaks down the total variation in the dependent variable into the variation explained by the independent variable(s) and the variation that is not explained by the independent variable(s). This is important because it helps us understand how much of the variation in the dependent variable can be attributed to the independent variable(s).\n",
    "\n",
    "The partitioning of variance in ANOVA is typically represented by the following equation:\n",
    "\n",
    "Total variation = Variation explained by independent variable(s) + Variation not explained by independent variable(s)\n",
    "\n",
    "The variation explained by the independent variable(s) is referred to as the \"between-group\" variation, while the variation not explained by the independent variable(s) is referred to as the \"within-group\" variation.\n",
    "\n",
    "Understanding the partitioning of variance is important in ANOVA because it helps us determine if there is a significant difference between the means of the different groups being compared. If the variation explained by the independent variable(s) (i.e., the between-group variation) is much larger than the variation not explained by the independent variable(s) (i.e., the within-group variation), then it suggests that there is a significant difference between the means of the groups being compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45424c8a-9a4b-4ca9-b893-415bcdc98d76",
   "metadata": {},
   "source": [
    "### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52682a4a-39b0-4339-a39f-3ad6aaf71dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST = 223.33333333333337\n",
      "SSE = 223.33333333333337\n",
      "SSR = 0.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# create three sample groups\n",
    "group1 = [10, 12, 14, 16, 18]\n",
    "group2 = [8, 11, 14, 17, 20]\n",
    "group3 = [9, 12, 15, 18, 21]\n",
    "\n",
    "# concatenate the groups\n",
    "data = group1 + group2 + group3\n",
    "\n",
    "# calculate the mean of the data\n",
    "mean = sum(data) / len(data)\n",
    "\n",
    "# calculate the total sum of squares (SST)\n",
    "SST = sum([(x - mean)**2 for x in data])\n",
    "\n",
    "# calculate the sum of squares between (SSB)\n",
    "SSB = len(group1) * (sum([(x - mean)**2 for x in group1]) / len(group1))\n",
    "SSB += len(group2) * (sum([(x - mean)**2 for x in group2]) / len(group2))\n",
    "SSB += len(group3) * (sum([(x - mean)**2 for x in group3]) / len(group3))\n",
    "\n",
    "# calculate the explained sum of squares (SSE)\n",
    "SSE = SSB\n",
    "\n",
    "# calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST =\", SST)\n",
    "print(\"SSE =\", SSE)\n",
    "print(\"SSR =\", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9836b-2c07-488e-9030-d391a6f6a7b7",
   "metadata": {},
   "source": [
    "### 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7969ff24-333b-4953-849f-3b391a8e96c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             df     sum_sq   mean_sq         F    PR(>F)\n",
      "C(Fertilizer)               1.0   0.033333  0.033333  0.012069  0.913305\n",
      "C(Watering)                 1.0   0.000369  0.000369  0.000133  0.990865\n",
      "C(Fertilizer):C(Watering)   1.0   0.040866  0.040866  0.014796  0.904053\n",
      "Residual                   28.0  77.333333  2.761905       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a dataframe\n",
    "dataframe = pd.DataFrame({'Fertilizer': np.repeat(['daily', 'weekly'], 15),\n",
    "\t\t\t\t\t\t'Watering': np.repeat(['daily', 'weekly'], 15),\n",
    "\t\t\t\t\t\t'height': [14, 16, 15, 15, 16, 13, 12, 11,\n",
    "\t\t\t\t\t\t\t\t\t14, 15, 16, 16, 17, 18, 14, 13,\n",
    "\t\t\t\t\t\t\t\t\t14, 14, 14, 15, 16, 16, 17, 18,\n",
    "\t\t\t\t\t\t\t\t\t14, 13, 14, 14, 14, 15]})\n",
    "\n",
    "\n",
    "# Performing two-way ANOVA\n",
    "model = ols('height ~ C(Fertilizer) + C(Watering) +\\\n",
    "C(Fertilizer):C(Watering)',\n",
    "\t\t\tdata=dataframe).fit()\n",
    "result = sm.stats.anova_lm(model, type=2)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74705cea-4c31-4a02-bb6e-8ca56f71f8ac",
   "metadata": {},
   "source": [
    "### 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7e354-1171-47e3-aad1-f1ddd3f2fcea",
   "metadata": {},
   "source": [
    "If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is at least one significant difference between the means of the groups being compared. The F-statistic tells us the ratio of the variance between the groups to the variance within the groups. A larger F-statistic indicates a greater difference between the group means compared to the variation within the groups. The p-value tells us the probability of obtaining a result as extreme as the observed result if there were no true differences between the groups.\n",
    "\n",
    "With a p-value of 0.02, we can interpret this result as follows: if there were no true differences between the groups, we would only expect to obtain a result as extreme as an F-statistic of 5.23 or higher by chance 2% of the time. Therefore, we reject the null hypothesis (that there are no true differences between the groups) and conclude that there is sufficient evidence to suggest that at least one of the group means is different from the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9492d9c-7705-4b6e-ba76-2518895adfe2",
   "metadata": {},
   "source": [
    "### 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1781523f-61ba-40c4-b0cf-fef2e10340a7",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, missing data can be handled in several ways:\n",
    "\n",
    "> Listwise deletion: This method involves excluding any cases with missing data from the analysis. This can be done using the dropna() function in pandas. While this approach is simple, it may result in a loss of statistical power if a large amount of data is missing.\n",
    "\n",
    "> Mean imputation: This method involves replacing missing values with the mean of the non-missing values. This can be done using the fillna() function in pandas. While this approach is simple and easy to implement, it may underestimate the variability of the data and result in biased estimates.\n",
    "\n",
    "> Last observation carried forward (LOCF): This method involves imputing missing values with the last observed value. This can be done using the fillna(method='ffill') function in pandas. While this approach is useful for data with a temporal order, it may not be appropriate for all situations and may result in biased estimates.\n",
    "\n",
    "> Multiple imputation: This method involves imputing missing values multiple times using a statistical model, and then combining the results to obtain estimates and standard errors. This can be done using the fancyimpute library in Python. While this approach is more sophisticated and can produce more accurate estimates than mean imputation or LOCF, it is computationally intensive and requires careful consideration of the underlying assumptions.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data in a repeated measures ANOVA include bias in the estimated means, standard errors, and effect sizes, as well as a loss of statistical power. It's important to carefully consider the underlying assumptions and potential limitations of each method and choose the approach that is most appropriate for the specific dataset and research question. Additionally, it may be beneficial to conduct sensitivity analyses to assess the robustness of the results to different methods of handling missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9373b-c48b-4bc6-8905-1599e0557ba1",
   "metadata": {},
   "source": [
    "### 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606336b-cad5-4326-8f38-69c5bd444bd5",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after ANOVA to make pairwise comparisons between groups when the overall ANOVA result is statistically significant. The purpose of post-hoc tests is to determine which specific groups differ from each other and to control for the familywise error rate, which is the probability of making at least one Type I error (false positive) across all the pairwise comparisons. Here are some common post-hoc tests used after ANOVA, along with an example of a situation where each one might be necessary:\n",
    "\n",
    "- Tukey's HSD (honestly significant difference) test: This test is a conservative post-hoc test that is commonly used when the sample sizes are equal across groups. It controls for the familywise error rate by adjusting the significance level for each pairwise comparison. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use Tukey's HSD test to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B and group C, but not group D, we can conclude that group A is significantly different from groups B and C, but not group D.\n",
    "\n",
    "- Bonferroni correction: This test is a simple and commonly used method to adjust the significance level for each pairwise comparison. It divides the significance level (usually 0.05) by the number of comparisons being made. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use the Bonferroni correction to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B, group C, and group D, we can conclude that group A is significantly different from all the other groups.\n",
    "\n",
    "- Dunnett's test: This test is used when we have one control group and several treatment groups. It compares each treatment group to the control group, while controlling for the overall familywise error rate. For example, if we have one control group and three treatment groups (A, B, C), and the overall ANOVA result is significant, we might use Dunnett's test to determine which specific treatment groups differ from the control group. If the test shows that group A is significantly different from the control group, but groups B and C are not significantly different from the control group, we can conclude that group A is significantly different from the control group, but groups B and C are not.\n",
    "\n",
    "- Scheffe's test: This test is a conservative post-hoc test that is used when the sample sizes are unequal across groups. It controls for the familywise error rate by adjusting the significance level for each pairwise comparison. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use Scheffe's test to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B and group C, but not group D, we can conclude that group A is significantly different from groups B and C, but not group D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0151d5a-677c-48c8-b91d-cee84fdc6612",
   "metadata": {},
   "source": [
    "### 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6c30ffb-f533-4936-abf7-62193f12fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 176.89689491604346\n",
      "p-value: 1.63227843737611e-28\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "diet_A = [4.2, 5.1, 3.7, 6.2, 4.9, 2.8, 5.4, 4.7, 3.9, 4.1,\n",
    "          3.3, 5.5, 4.8, 5.3, 3.9, 6.1, 4.3, 3.5, 5.2, 5.0,\n",
    "          5.6, 3.8, 5.8, 4.0, 5.7]\n",
    "diet_B = [2.9, 1.9, 2.5, 2.3, 3.2, 2.7, 1.8, 3.1, 2.6, 3.0,\n",
    "          2.4, 2.0, 2.8, 2.2, 2.1, 2.6, 2.7, 1.6, 2.4, 2.9,\n",
    "          3.0, 1.8, 2.1, 2.3, 2.6]\n",
    "diet_C = [1.3, 0.9, 1.1, 1.6, 1.4, 1.8, 1.2, 1.5, 2.0, 1.4,\n",
    "          1.7, 1.3, 1.9, 1.0, 1.6, 1.2, 1.8, 1.4, 1.1, 1.7,\n",
    "          1.5, 1.6, 1.9, 1.2, 1.4]\n",
    "\n",
    "# One-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6976480-8c1d-4f7c-ac35-83703e22924b",
   "metadata": {},
   "source": [
    "### 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab8ea24-8451-4099-b91b-cbce1a47583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data example :\n",
      "  Software Experience       Time\n",
      "0        A     Novice  12.828739\n",
      "1        A     Novice  16.994691\n",
      "2        A     Novice  15.565957\n",
      "3        A     Novice  11.987411\n",
      "4        A     Novice  13.842799\n",
      "\n",
      "**********************************************************\n",
      "\n",
      "                             df      sum_sq     mean_sq          F  \\\n",
      "C(Software)                 2.0  204.881181  102.440590  18.135666   \n",
      "C(Experience)               1.0  165.079097  165.079097  29.224933   \n",
      "C(Software):C(Experience)   2.0   17.481552    8.740776   1.547431   \n",
      "Residual                   56.0  316.319953    5.648571        NaN   \n",
      "\n",
      "                                 PR(>F)  \n",
      "C(Software)                8.460472e-07  \n",
      "C(Experience)              1.375177e-06  \n",
      "C(Software):C(Experience)  2.217544e-01  \n",
      "Residual                            NaN  \n",
      "\n",
      "\n",
      "Conclusion: There is a significant main effect of software.\n",
      "Conclusion: There is a significant main effect of experience.\n",
      "Conclusion: There is no significant interaction effect between software and experience.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generating 2 random time samples for novice and expert\n",
    "time_novice = np.random.normal(loc=15, scale=2, size=30)\n",
    "time_expert = np.random.normal(loc=10, scale=2, size=30)\n",
    "\n",
    "# Generate simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A']*20 + ['B']*20 + ['C']*20,\n",
    "    'Experience': ['Novice']*30 + ['Experienced']*30,\n",
    "    'Time': list(time_novice)+list(time_expert)\n",
    "})\n",
    "\n",
    "# Print the simulated data head \n",
    "print('Simulated Data example :')\n",
    "print(data.head())\n",
    "\n",
    "print('\\n**********************************************************\\n')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Main effects and interaction effect\n",
    "print(table)\n",
    "print('\\n')\n",
    "if table['PR(>F)'][0] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of software.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of software.\")\n",
    "\n",
    "if table['PR(>F)'][1] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of experience.\")\n",
    "\n",
    "if table['PR(>F)'][2] < alpha:\n",
    "    print(\"Conclusion: There is a significant interaction effect between software and experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant interaction effect between software and experience.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175120f-2fe0-4727-b51a-540d44c2fbde",
   "metadata": {},
   "source": [
    "### 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326e890c-d884-4325-b2c7-2f9d242c41e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated data for test_scores:\n",
      "   test_score    group\n",
      "0   70.079124  control\n",
      "1   70.780965  control\n",
      "2   68.814563  control\n",
      "3   69.387097  control\n",
      "4   66.185102  control\n",
      "\n",
      "************************\n",
      "\n",
      "t-statistic: -28.5074, p-value: 3.096206271894725e-49\n",
      "\n",
      "\n",
      "Reject the Null Hypothesis\n",
      "Conclusion : There is SIGNIFICANT difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Setting numpy random seed\n",
    "np.random.seed(45)\n",
    "\n",
    "# Generating normal test scores with same variance for both control groups\n",
    "test_score_control = np.random.normal(loc=70, scale=3, size=50)\n",
    "test_score_experimental = np.random.normal(loc=85, scale=3, size=50)\n",
    "\n",
    "# Creating the dataframe\n",
    "df = pd.DataFrame({'test_score':list(test_score_control)+list(test_score_experimental),\n",
    "                   'group':['control']*50 + ['experimental']*50})\n",
    "\n",
    "# printing the sample dataframe\n",
    "print('Simulated data for test_scores:')\n",
    "print(df.head())\n",
    "print('\\n************************\\n')\n",
    "\n",
    "null_hypothesis = \"There is NO difference in test scores between the control and experimental groups.\"\n",
    "alt_hypothesis = \"There is SIGNIFICANT difference in test scores between the control and experimental groups.\"\n",
    "\n",
    "# Conduct the two-sample t-test\n",
    "control_scores = df[df['group'] == 'control']['test_score']\n",
    "experimental_scores = df[df['group'] == 'experimental']['test_score']\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores, equal_var=True)\n",
    "print(f\"t-statistic: {t_stat:.4f}, p-value: {p_val}\")\n",
    "print('\\n')\n",
    "\n",
    "# Significance value \n",
    "alpha = 0.05\n",
    "if p_val<alpha:\n",
    "    print('Reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {alt_hypothesis}')\n",
    "else:\n",
    "    print('Failed to reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {null_hypothesis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a288d3-84d6-402a-b9bc-de556d8ecd19",
   "metadata": {},
   "source": [
    "### 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd60122-1198-4cdf-a7bd-28c9fd972e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data top 5 rows : \n",
      "   Day    Store        Sales\n",
      "0    0  Store A   933.187150\n",
      "1    1  Store A   950.179048\n",
      "2    2  Store A  1061.857582\n",
      "3    3  Store A  1056.869225\n",
      "4    4  Store A  1135.050948\n",
      "\n",
      "_______________________________\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store 51.5040 2.0000 58.0000 0.0000\n",
      "===================================\n",
      "\n",
      "Reject the Null Hypothesis : Atleast one of the group has different mean.\n",
      "\n",
      "Tukey HSD posthoc test:\n",
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "===========================================================\n",
      " group1  group2  meandiff p-adj    lower     upper   reject\n",
      "-----------------------------------------------------------\n",
      "Store A Store B   21.2439 0.6945   -40.881   83.3688  False\n",
      "Store A Store C -207.8078    0.0 -269.9328 -145.6829   True\n",
      "Store B Store C -229.0517    0.0 -291.1766 -166.9268   True\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(456)\n",
    "\n",
    "# generate sales data for Store A, B, and C\n",
    "sales_a = np.random.normal(loc=1000, scale=100, size=(30,))\n",
    "sales_b = np.random.normal(loc=1050, scale=150, size=(30,))\n",
    "sales_c = np.random.normal(loc=800, scale=80, size=(30,))\n",
    "\n",
    "# create a DataFrame to store the sales data\n",
    "sales_df = pd.DataFrame({'Store A': sales_a, 'Store B': sales_b, 'Store C': sales_c})\n",
    "\n",
    "# reshape the DataFrame for repeated measures ANOVA\n",
    "sales_melted = pd.melt(sales_df.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\n",
    "sales_melted.columns = ['Day', 'Store', 'Sales']\n",
    "\n",
    "# Printing top 5 rows of generated data\n",
    "print('Generated data top 5 rows : ')\n",
    "print(sales_melted.head())\n",
    "\n",
    "print('\\n_______________________________\\n')\n",
    "\n",
    "# perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(sales_melted, 'Sales', 'Day', within=['Store'])\n",
    "rm_results = rm_anova.fit()\n",
    "print(rm_results)\n",
    "\n",
    "# check if null hypothesis should be rejected based on p-value\n",
    "if rm_results.anova_table['Pr > F'][0] < 0.05:\n",
    "    # perform post-hoc Tukey test\n",
    "    print('Reject the Null Hypothesis : Atleast one of the group has different mean.\\n')\n",
    "    print('Tukey HSD posthoc test:')\n",
    "    tukey_results = pairwise_tukeyhsd(sales_melted['Sales'], sales_melted['Store'])\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print('NO significant difference between groups.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
