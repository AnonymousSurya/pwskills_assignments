{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e7c8a0c",
   "metadata": {},
   "source": [
    "#### Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30086218",
   "metadata": {},
   "source": [
    "Lasso Regression is a type of linear regression that uses L1 regularization to prevent overfitting of the model. lasso regression is regularization technique which is used as features selection. and also known as l1 regularization. it add penalties and shrink coefficient towards the zero.\n",
    "The main difference is that lasso can set the value as zero to coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc4fc4",
   "metadata": {},
   "source": [
    "#### Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589397be",
   "metadata": {},
   "source": [
    "Advantage:\n",
    "- Feature selection when the dataset is large.\n",
    "- Can handle collinear features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b227e",
   "metadata": {},
   "source": [
    "#### Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab931dd",
   "metadata": {},
   "source": [
    "Hence the lasso regression shrinks the coefficient towards the zero and set as zero.\n",
    "if coefficient value is zero than that particular feature does not have any impact on target features we can drop that particular features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa64cc",
   "metadata": {},
   "source": [
    "#### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787f794",
   "metadata": {},
   "source": [
    "In Lasso Regression, the tuning parameter that can be adjusted is the regularization parameter, also known as the lambda parameter.\n",
    "lambda controls the amount of regularization applied to the model and can be adjusted to balance between model complexity and accuracy.\n",
    "The lambda parameter determines the degree of shrinkage applied to the coefficients.\n",
    "The high value of lambda results in higher shrinkage and lower the value result in lower shrinkage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac63178",
   "metadata": {},
   "source": [
    "#### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77359c",
   "metadata": {},
   "source": [
    "Lasso regression is a type of linear regression that is commonly used for feature selection and regularization. It is based on the L1 regularization method, which adds a penalty term to the objective function that is proportional to the absolute values of the regression coefficients.\n",
    "however it is not suitable for non-linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09c114",
   "metadata": {},
   "source": [
    "#### Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a2a34",
   "metadata": {},
   "source": [
    "Both regularization technique commonly used in linear regression to prevent overfitting and improve model performance.\n",
    "The main difference between Ridge and Lasso regression is the penalty term that is added to the objective function. Ridge regression adds a penalty term that is proportional to the square of the regression coefficients (L2 regularization), while Lasso regression adds a penalty term that is proportional to the absolute values of the regression coefficients (L1 regularization).\n",
    "\n",
    "\n",
    "Feature Selection: Ridge regression shrinks the coefficients towards zero, but does not set them exactly to zero. Therefore, it is not suitable for feature selection. On the other hand, Lasso regression can set some of the coefficients exactly to zero, effectively performing feature selection by excluding certain predictors from the model.\n",
    "\n",
    "Stability: Ridge regression is more stable than Lasso regression when there are collinearities (high correlations) among the predictors. Lasso regression tends to be unstable and may produce different results depending on which predictors are included in the model.\n",
    "\n",
    "Interpretation: Ridge regression can be more difficult to interpret because it does not eliminate any predictors from the model. Lasso regression, on the other hand, can be easier to interpret because it eliminates some predictors and sets their coefficients to zero.\n",
    "\n",
    "Computational Complexity: Lasso regression can be more computationally intensive than Ridge regression, especially when the number of predictors is large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed8c02e",
   "metadata": {},
   "source": [
    "#### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c893f9",
   "metadata": {},
   "source": [
    "Lasso regression can handle multicollinearity in the input features to some extent, but it may not completely eliminate it. Multicollinearity occurs when two or more predictor variables in a regression model are highly correlated with each other, which can cause instability and inaccuracies in the estimated coefficients.\n",
    "\n",
    "Lasso regression addresses multicollinearity by shrinking the regression coefficients towards zero, which can reduce the impact of correlated predictors on the response variable. However, in cases where there is high multicollinearity, Lasso may not be able to effectively distinguish between the correlated predictors, resulting in inconsistent and unpredictable coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d6389d",
   "metadata": {},
   "source": [
    "#### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd79a7",
   "metadata": {},
   "source": [
    "Here are some common methods to choose the optimal value of lambda in Lasso regression:\n",
    "\n",
    "1. Cross-validation: One of the most common methods to choose the optimal value of lambda is through cross-validation. In k-fold cross-validation, the data is split into k equal parts, and the model is trained on k-1 folds and validated on the remaining fold. This process is repeated k times, and the average validation error is used to choose the optimal value of lambda that minimizes the validation error.\n",
    "\n",
    "2. Grid search: Another method to choose the optimal value of lambda is through a grid search, where a range of lambda values is specified, and the model is trained and validated for each lambda value. The optimal value of lambda is chosen based on the validation error or another metric such as R-squared or mean squared error.\n",
    "\n",
    "3. Bayesian methods: Bayesian methods can also be used to choose the optimal value of lambda by placing a prior distribution on lambda and updating it based on the observed data. The posterior distribution of lambda can be used to estimate the optimal value of lambda that maximizes the posterior probability.\n",
    "\n",
    "4. Information criteria: Information criteria such as Akaike information criterion (AIC) or Bayesian information criterion (BIC) can also be used to choose the optimal value of lambda that minimizes the information criterion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
